# -*- coding: utf-8 -*-
"""Final_Pest_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17Yq1FvDgDDce5En5NYLKHW3etF1c-5lv
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
import os
import numpy as np
import keras
from keras import models, layers, optimizers
from keras.applications import vgg16, resnet50
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.imagenet_utils import decode_predictions
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from keras.models import load_model

mode="train"

# loading the directories 
train_dir = '/content/drive/My Drive/Pest_dataset/train'
val_dir = '/content/drive/My Drive/Pest_dataset/Val'

classes_count = 10


image_size = 128

history = None

if mode == "train":
    # VGG16 base
    vgg_model = vgg16.VGG16(weights="imagenet", include_top=False, input_shape=(image_size, image_size, 3))
    base_model = vgg16.VGG16
    trainable_layers = 4

base_model = base_model(weights="imagenet", include_top=False, input_shape=(image_size, image_size, 3))

for layer in base_model.layers[:-trainable_layers]:
        layer.trainable = False

# Check the trainable status of the individual layers
for layer in base_model.layers:
        print(layer, layer.trainable)

# Create our new model
pest_model = models.Sequential()

# Add the vgg convolutional base model
pest_model.add(base_model)

# Add new layers
pest_model.add(layers.Flatten())
pest_model.add(layers.Dense(1024, activation="relu"))
pest_model.add(layers.Dropout(0.5))
pest_model.add(layers.Dense(classes_count, activation="softmax"))

pest_model.summary()

train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        horizontal_flip=True,
        fill_mode="nearest")
validation_datagen = ImageDataGenerator(
        rescale=1./255
    )

train_batchsize = 22
validation_batchsize = 5

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_size, image_size),
        batch_size=train_batchsize,
        class_mode="categorical"
    )  

validation_generator = validation_datagen.flow_from_directory(
        val_dir,
        target_size=(image_size, image_size),
        batch_size=validation_batchsize,
        class_mode="categorical",
        shuffle=False
)

# Set up early stopping
early_stop = keras.callbacks.EarlyStopping(
        monitor="val_loss",
        min_delta=0,
        patience=10,
        verbose=0,
        mode="auto"
    )

# Compile the model
pest_model.compile(
        loss="categorical_crossentropy",
        optimizer=optimizers.RMSprop(lr=1e-4),
        metrics=["acc"]
    )

# Train the model
history = pest_model.fit_generator(
        train_generator,
        callbacks=[early_stop],
        steps_per_epoch=train_generator.samples/train_generator.batch_size,
        epochs=25,
        
        validation_data=validation_generator,
        validation_steps=validation_generator.samples/validation_batchsize,
        verbose=1
    )

# Save the model
pest_model.save("/content/drive/My Drive/pest_final_model.h5")

#Confution Matrix and Classification Report
from sklearn.metrics import confusion_matrix,classification_report
Y_pred = pest_model.predict_generator(validation_generator, validation_generator.samples/ validation_batchsize)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
print(confusion_matrix(validation_generator.classes, y_pred))
print('Classification Report')
target_names = ['White_Grub', 'Mole_Cricket', 'Wireworm','Cutworm','Moth','Red_spider','Armyworm','Aphids','Potosiabre_vitarsis','Thrips']
print(classification_report(validation_generator.classes, y_pred, target_names=target_names))

acc=history.history['acc']
val_acc=history.history['val_acc']
loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(1,len(acc)+1)

#Tranning and validation accuracy
plt.plot(epochs,acc,'b',label='Training Accuracy')
plt.plot(epochs,val_acc,'r',label='Validation Accuracy')
plt.title('Training Validation Accuracy')
plt.legend()

plt.figure()

plt.plot(epochs,loss,'b',label='Training Loss')
plt.plot(epochs,val_loss,'r',label='Validation Loss')
plt.title('Training Validation Loss')
plt.legend()
plt.figure()